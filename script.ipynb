{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sent': [71497], 'Opens': [4344], 'Individual Opens': [3498]} {'subject_line': 'Our network is expanding, are you taking advantage', 'company': 'NEOS Networks'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Backend\\Python\\web_scrape\\Product\\script.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 438>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=435'>436</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=436'>437</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTo run analysis please provide colours for the company: \u001b[39m\u001b[39m{\u001b[39;00mclient_info[\u001b[39m\"\u001b[39m\u001b[39mcompany\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=437'>438</a>\u001b[0m get_basic_info(company, stats_url\u001b[39m=\u001b[39;49mstats_url)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=438'>439</a>\u001b[0m clear_directories()\n",
      "\u001b[1;32mc:\\Backend\\Python\\web_scrape\\Product\\script.ipynb Cell 1\u001b[0m in \u001b[0;36mget_basic_info\u001b[1;34m(company, stats_url)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=432'>433</a>\u001b[0m \u001b[39m##run analysis\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=433'>434</a>\u001b[0m \u001b[39mif\u001b[39;00m client_info[\u001b[39m'\u001b[39m\u001b[39mcompany\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m clients:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=434'>435</a>\u001b[0m     analysis_and_visualisation(subject_line\u001b[39m=\u001b[39;49mclient_info[\u001b[39m'\u001b[39;49m\u001b[39msubject_line\u001b[39;49m\u001b[39m'\u001b[39;49m], company\u001b[39m=\u001b[39;49mclient_info[\u001b[39m'\u001b[39;49m\u001b[39mcompany\u001b[39;49m\u001b[39m'\u001b[39;49m], colours\u001b[39m=\u001b[39;49mclients[client_info[\u001b[39m'\u001b[39;49m\u001b[39mcompany\u001b[39;49m\u001b[39m'\u001b[39;49m]], generic_df\u001b[39m=\u001b[39;49mgeneric_df, handicap\u001b[39m=\u001b[39;49mhandicap, abbrv\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m?utm_source\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=435'>436</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=436'>437</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTo run analysis please provide colours for the company: \u001b[39m\u001b[39m{\u001b[39;00mclient_info[\u001b[39m\"\u001b[39m\u001b[39mcompany\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Backend\\Python\\web_scrape\\Product\\script.ipynb Cell 1\u001b[0m in \u001b[0;36manalysis_and_visualisation\u001b[1;34m(company, subject_line, colours, generic_df, handicap, abbrv)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m links:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=258'>259</a>\u001b[0m     \u001b[39mif\u001b[39;00m abbrv:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=259'>260</a>\u001b[0m         label \u001b[39m=\u001b[39m x[:x\u001b[39m.\u001b[39;49mindex[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mabbrv\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m]]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=260'>261</a>\u001b[0m     \u001b[39melse\u001b[39;00m: \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Backend/Python/web_scrape/Product/script.ipynb#W0sZmlsZQ%3D%3D?line=261'>262</a>\u001b[0m         label \u001b[39m=\u001b[39mx\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from math import inf\n",
    "import os\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import csv\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "username = 'jubah@bpl-business.com'\n",
    "company = 'ite'\n",
    "stats_url = 'https://iteuropa.circdata-solutions.co.uk/Fusion/Dynamail/MailshotDetails.aspx?id=894cf72b-1c07-4430-b5d7-082f41391d9f'\n",
    "\n",
    "clients = {\n",
    "    'Union Street': ['#00509f', '#e6aaaa'],\n",
    "    'Akixi': ['#035496', '#efc52f'],\n",
    "    'Fibre Provider': ['#ef7b2f', '#1f2937'],\n",
    "    'Managed Services': ['#e8653f','#2d2d2d'],\n",
    "    'Comms Dealer Weekly': ['#274083','#b2b2b8'],\n",
    "    'Jola':['#009fe3','#000000'],\n",
    "    'NEOS':['#31968c','#dc7f3a'],\n",
    "    'NEOS Networks':['#31968c','#dc7f3a'],\n",
    "    'ITE Weekly': ['#003b6a','#5d9fbc'],\n",
    "    'Nuvias':['#2a6c88','#f6c576'],\n",
    "    'Evolve IP':['#f47920','#0451a1']\n",
    "}\n",
    "\n",
    "handicap = 1\n",
    "\n",
    "credentials ={\n",
    "    'ite': {\n",
    "        'password':'ITCrowdRules!',\n",
    "         'url': 'https://iteuropa.circdata-solutions.co.uk/Fusion/login.aspx',\n",
    "         '__VIEWSTATE' : '/wEPDwUKMTgwMjQwMDI5M2Rksovo2zHemSveuJw8vAuQ6Xf8InA=',\n",
    "         '__EVENTVALIDATION' : '/wEWBQKPgenHBQLj+sxGAuOoubQBAqqg8cUOAteSgYoCZ204OWUV6uw8bUTN6GYNlbZWM7E=',\n",
    "        'bot_links':['https://www.iteuropa.com/privacy-policy?ref=email_footer', 'https://www.iteuropa.com/communication-preferences?email=[CD|emailaddress|]','https://www.iteuropa.com/?utm_source=newsletter&utm_medium=email&utm_campaign=weekly&utm_content=pixel','mailto:clients@ite-mail1.com', 'http://www.iteuropa.com', 'https://www.iteuropa.com?ref=email_footer','http://www.iteuropa.com/?q=privacy-policy','http://www.iteuropa.com/','http://www.iteuropa.com/communication-preferences?email=[CD|emailaddress|]']\n",
    "        },\n",
    "    'bpl':  {\n",
    "        'password':'Acumagic10', \n",
    "        'url': 'https://bpl.circdata-solutions.co.uk/Fusion/login.aspx',\n",
    "        '__VIEWSTATE':'/wEPDwUKMTgwMjQwMDI5M2Rk2e1SYhd3ZcfIKWr+jOok9jgKqtU=',\n",
    "        '__EVENTVALIDATION':'/wEWBQLV2djbAQLj+sxGAuOoubQBAqqg8cUOAteSgYoC7owPjxk9TLLjh/iR0zoJPMA+4Yk=',\n",
    "        'bot_links':['http://www.bpl-business.com','https://www.bpl-business.com', 'http://www.bpl-business.com/privacy-policy.shtml','https://www.bpl-business.com/privacy-policy','mailto:weeklynews@bpl-mail1.co.uk','https://www.fibreprovider.net/?utm_source=newsletter&utm_medium=email&utm_campaign=weekly&utm_content=pixel']\n",
    "        \n",
    "}\n",
    "}\n",
    "\n",
    "def clear_directories():\n",
    "    shutil.rmtree(f'{os.getcwd()}\\\\company')\n",
    "    shutil.rmtree(f'{os.getcwd()}\\\\pixels')\n",
    "\n",
    "def isBannedCharacter(character):\n",
    "    if ord(character) >= 128:\n",
    "        return True\n",
    "\n",
    "def remove_characters(string):\n",
    "    unallowed = ['#', '<', '>', '%', '&', '{', '}', '/', '$', '!', '\\'', '\\\"', ':', '@','*','?','\\\\','+','+','`','|','=','â€“' ]\n",
    "    sanitised_string =''\n",
    "    for character in range(len(string)):\n",
    "        if not string[character] in unallowed and not isBannedCharacter(string[character]):\n",
    "            sanitised_string = sanitised_string + string[character]\n",
    "    return sanitised_string\n",
    "\n",
    "\n",
    "def analysis_and_visualisation(company, subject_line, colours, generic_df, handicap, abbrv=None):\n",
    "    \n",
    "    year = date.today().year\n",
    "    month = date.today().month\n",
    "    day = date.today().day\n",
    "    time_stamp = f\"{day}-{month}-{year}\"\n",
    "\n",
    "    path = os.getcwd()\n",
    "    pixels_path = path + \"\\\\pixels\"\n",
    "    company_path = path + \"\\\\company\"\n",
    "\n",
    "    pixel_files = glob.glob(os.path.join(pixels_path, \"*.csv\"))\n",
    "    comp_files = glob.glob(os.path.join(company_path, \"*.csv\"))\n",
    "\n",
    "    df_comp = pd.concat((pd.read_csv(file, parse_dates=[1,2,4],index_col=False) for file in comp_files), ignore_index=True)\n",
    "    \n",
    "    if len(pixel_files)>0:\n",
    "        df_px = pd.concat((pd.read_csv(file, parse_dates=[1,2,4],index_col=False) for file in pixel_files), ignore_index=True)\n",
    "        df = df_comp[~df_comp.Email.isin(df_px.Email)].reset_index(drop=True)\n",
    "    else:\n",
    "        df = df_comp\n",
    "    \n",
    "    #grab all files\n",
    "    #########################################################################################################\n",
    "\n",
    "\n",
    "    #########################################################################################################\n",
    "\n",
    "    if df.empty:\n",
    "        end=''\n",
    "        print('dataframe is empty - no clicks')\n",
    "        return None\n",
    "    else:\n",
    "    \n",
    "        #Remove pixel emails from the main dataframe\n",
    "        #########################################################################################################\n",
    "\n",
    "\n",
    "        listed_columns = list(df.columns)\n",
    "        df.drop(df.columns[listed_columns.index('BounceDate'):], axis=1, inplace=True)\n",
    "     \n",
    "\n",
    "        #########################################################################################################\n",
    "\n",
    "        df['Company'] = df.apply(lambda row: row.Email.split('@')[1][: row.Email.split('@')[1].index('.')], axis=1) \n",
    "        \n",
    "        #Here we are adding a new column 'company' that will let us track bot companies\n",
    "        #########################################################################################################\n",
    "\n",
    "\n",
    "        df['name'] = df.apply(lambda row: row.Email.split('@')[0].lower(), axis=1) \n",
    "        df['Bot_Likelihood'] = 0\n",
    "        fake_people = ['info', 'sales', 'marketing', 'operations','hello','contact']\n",
    "\n",
    "        df = df[~df.name.isin(fake_people)].reset_index(drop=True)\n",
    "\n",
    "        time_data = {}\n",
    "        company_trends = {}\n",
    "\n",
    "        for person in df.Email:\n",
    "            clicks = df[df.Email == person].LinkClickedDate.reset_index(drop =True)\n",
    "            Open_Send_Sum = df[df.Email == person].OpenedDate - df[df.Email == person].SentDate\n",
    "\n",
    "            company_search = df[df.Email == person].Company.values[0]\n",
    "            if not company_search in company_trends:\n",
    "                company_trends[company_search]=[]\n",
    "            company_trends[company_search].append(Open_Send_Sum.values[0] / np.timedelta64(1, 's'))\n",
    "            time_data[person] = clicks\n",
    "    \n",
    "        \n",
    "        for company_x in company_trends:\n",
    "            company_data = company_trends[company_x]\n",
    "            deviation=np.std(company_data)/np.mean(company_data)\n",
    "            company_trends[company_x]=deviation\n",
    "            if deviation < 0.6 and len(company_data) > len(comp_files) :\n",
    "                includes_bad_company = df.index[df['Company'] == company_x].tolist()\n",
    "                for index in includes_bad_company:\n",
    "                    df.at[index, 'Bot_Likelihood'] = (3/5)\n",
    "        \n",
    "        #########################################################################################################\n",
    "\n",
    "        \n",
    "        #get clickers that clicked too quickly\n",
    "        bots = []\n",
    "        bot_companies = ['bpl-business', 'iteuropa']\n",
    "        number_of_links = len(comp_files)\n",
    "        allowance = 0.75\n",
    "        if number_of_links > 5:\n",
    "            allowance = allowance * number_of_links ** - (1/8)\n",
    "         \n",
    "\n",
    "\n",
    "        for clicker in time_data:\n",
    "            botness = df[df.Email == clicker].Bot_Likelihood.reset_index(drop=True)[0]\n",
    "            clicks = list(time_data[clicker])\n",
    "            clicks.sort()\n",
    "            clicker_index = df.index[df['Email'] == clicker].tolist()\n",
    "            \n",
    "            failed = {\n",
    "                'click_gap': False,\n",
    "                'many_links':False,\n",
    "                'many_links_short_gap':False\n",
    "            }\n",
    "\n",
    "\n",
    "            too_soon = timedelta(seconds=handicap)\n",
    "            shortest_time = timedelta(seconds=-1)\n",
    "\n",
    "            length = len(clicks)\n",
    "        \n",
    "            if length:\n",
    "                for i in range(length-1):\n",
    "                    gap = clicks[i+1]- clicks[i]\n",
    "                \n",
    "                    if (gap > shortest_time and gap <= too_soon):\n",
    "                        failed['click_gap'] = True\n",
    "\n",
    "                        comp = df[df.Email == clicker].Company.reset_index(drop=True)[0] \n",
    "                        if not comp in bot_companies:\n",
    "                            bot_companies.append(comp)\n",
    "            \n",
    "                percentage_clicks = length / number_of_links\n",
    "                if percentage_clicks > allowance:\n",
    "                    failed['many_links'] = True\n",
    "                    for i in range(length -1):\n",
    "                        gap = clicks[i+1] - clicks[i]\n",
    "                        if (gap > shortest_time and gap <= timedelta(seconds=5)):\n",
    "                            failed['many_links_short_gap'] = True\n",
    "\n",
    "            if failed['click_gap']:\n",
    "                botness+=(2/3)\n",
    "            if failed['many_links']:\n",
    "                botness += (1/4)\n",
    "            if failed['many_links_short_gap']:\n",
    "                botness += (1/4)\n",
    "\n",
    "\n",
    "            for index in clicker_index:\n",
    "                df.at[index, 'Bot_Likelihood'] = botness\n",
    "                    \n",
    "        for x in bot_companies:\n",
    "            bad_by_association = df.index[df['Company'] == x].tolist()\n",
    "            for index in bad_by_association:\n",
    "                new_rating = df.iloc[index].Bot_Likelihood + (1/6)\n",
    "                df.at[index, 'Bot_Likelihood'] = new_rating\n",
    "\n",
    "        sanitised = df[df.Bot_Likelihood < (1/3) ].reset_index(drop=True)\n",
    "        sanitised_columns = list(sanitised.columns)\n",
    "        product_csv =  sanitised.drop(sanitised.columns[sanitised_columns.index('Company'):], axis=1)\n",
    "\n",
    "        ##make holding directories\n",
    "\n",
    "        parent_dir = f\"{os.getcwd()}\\\\Completed_Reports\"\n",
    "        dir_path = f\"{os.getcwd()}\\\\Completed_Reports\\\\{company}\"\n",
    "\n",
    "        dir_exists = os.path.isdir(dir_path)\n",
    "\n",
    "        if not dir_exists:\n",
    "            os.mkdir(dir_path)\n",
    "        os.mkdir(f\"{os.getcwd()}\\\\Completed_Reports\\\\{company}\\\\{subject_line}\")\n",
    "        dir_path = f\"{os.getcwd()}\\\\Completed_Reports\\\\{company}\\\\{subject_line}\"\n",
    "            \n",
    "        df.to_csv(f\"{dir_path}\\\\bot-analysis-{subject_line}.csv\",index=False)\n",
    "        product_csv.to_csv(f\"{dir_path}\\\\{subject_line}-clickStats.csv\",index=False)\n",
    "        sanitised.to_csv(f\"{dir_path}\\\\who_passed_{subject_line}.csv\",index=False)\n",
    "        generic_df.to_csv(f'{dir_path}\\\\{subject_line}-genericStats.csv', index=False)\n",
    "\n",
    "        links = {}\n",
    "        for link in sanitised.LinkUrl:\n",
    "            if link in links:\n",
    "                links[link] +=1\n",
    "            else:\n",
    "                links[link] =1\n",
    "\n",
    "\n",
    "        links_Y = []\n",
    "        links_Xticks = []\n",
    "        color_scheme =[]\n",
    "        colors = colours\n",
    "        index = 0\n",
    "\n",
    "\n",
    "\n",
    "        for x in links:\n",
    "            \n",
    "            if abbrv:\n",
    "                label = x[:x.index(f'{abbrv}')]\n",
    "            else: \n",
    "                label =x\n",
    "            links_Xticks.append(f\"Link: {label}, {links[x]} click(s)\")\n",
    "            links_Y.append(links[x])\n",
    "            if index % 2 ==0:\n",
    "                color_scheme.append(colors[0])\n",
    "            else:\n",
    "                color_scheme.append(colors[1])\n",
    "            index +=1\n",
    "\n",
    "        if (len(links)<2):\n",
    "            links_Xticks.append(f\"No other links clicked\")\n",
    "            links_Y.append(0)\n",
    "            color_scheme.append(colors[1])\n",
    "\n",
    "\n",
    "        print(color_scheme)\n",
    "        plt.barh(links_Xticks, links_Y, color=color_scheme)\n",
    "        plt.title(f'Click stats for {company} campaign: {subject_line}')\n",
    "        plt.xlabel('clicks')\n",
    "        plt.savefig(f\"{dir_path}\\\\{subject_line}-ecast-stats.pdf\", bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def get_basic_info(company, stats_url):\n",
    "\n",
    "    ## Login to dynamail\n",
    "    webpage_response = req.get(credentials[company]['url'])\n",
    "    webpage = webpage_response.content\n",
    "\n",
    "     ##login input fields\n",
    "\n",
    "    login_creds = {\n",
    "        'ctl00$CPHP$newloginControl$tbUsername': username,\n",
    "        'ctl00$CPHP$newloginControl$tbPassword': credentials[company]['password'],\n",
    "        'ctl00$CPHP$newloginControl$loginButton': 'Login',\n",
    "        '__VIEWSTATEGENERATOR': '5E82A05A',\n",
    "        '__VIEWSTATE': credentials[company]['__VIEWSTATE'],\n",
    "        '__EVENTVALIDATION': credentials[company]['__EVENTVALIDATION'],\n",
    "    }\n",
    "\n",
    "    session = req.session()\n",
    "    res = session.post(credentials[company]['url'], data=login_creds)\n",
    "\n",
    "\n",
    "    ####################################################################\n",
    "    #   Go to specific url#######\n",
    "    stats_page = session.get(stats_url)\n",
    "    stats_page_soup = BeautifulSoup(stats_page.content, 'html.parser')\n",
    "\n",
    "\n",
    "    generic_stats ={\n",
    "        'Sent': [0],\n",
    "        'Opens':[0],\n",
    "        'Individual Opens':[0]\n",
    "    }\n",
    "\n",
    "    client_info = {\n",
    "        'subject_line': '',\n",
    "        'company':''\n",
    "    }\n",
    "\n",
    "\n",
    "    ####get total_Sent\n",
    "    labels = stats_page_soup.find_all(attrs={'class':'Label'})\n",
    "\n",
    "    for x in labels:\n",
    "\n",
    "        if(x.string.find('Emails') > 0):   \n",
    "            generic_stats['Sent'][0] = int(x.parent.find_all('td')[1].find('a').string)\n",
    "        if(x.string.find('Subject') > 0):\n",
    "            client_info['subject_line'] = x.parent.find_all('td')[1].string\n",
    "        if(x.string.find('Campaign') > 0):\n",
    "            client_info['company'] = x.parent.find_all('td')[1].find('a').string\n",
    "        \n",
    "\n",
    "    ##### get opened and unique opens\n",
    "    unique_opens_img = stats_page_soup.find('img', attrs={'id': 'ctl00_CPHP_mailshotCharts_EmailsByStatusChart_Chart1'}).parent.find_all('area')[1].attrs['title']\n",
    "    unique_opens = int(unique_opens_img[unique_opens_img.index('- ')+1:])\n",
    "    generic_stats['Individual Opens'][0] = unique_opens\n",
    "\n",
    "    overall_opens = int(stats_page_soup.find('span', attrs={'id':'ctl00_CPHP_mailshotCharts_OpenedEmailsLabel'}).find('b').text)\n",
    "    generic_stats['Opens'][0] = overall_opens\n",
    "\n",
    "    ### santise subject line and subject_line\n",
    "    start_slice = inf\n",
    "    end_slice = None\n",
    "    for x in client_info['subject_line']:\n",
    "        if(x != ' ' and x !='\\n' and x != '\\r\\n' and x != '\\r'):\n",
    "            end_slice = client_info['subject_line'].rindex(x)\n",
    "            if(client_info['subject_line'].index(x) < start_slice):\n",
    "                start_slice = client_info['subject_line'].index(x)\n",
    "    client_info['subject_line'] = remove_characters(client_info['subject_line'][start_slice:end_slice+1])\n",
    "\n",
    "\n",
    "    ### santise company and subject_line\n",
    "    start_slice = inf\n",
    "    end_slice = None\n",
    "    for x in client_info['company']:\n",
    "        if(x != ' ' and x !='\\n' and x != '\\r\\n' and x != '\\r'):\n",
    "            end_slice = client_info['company'].rindex(x)\n",
    "            if(client_info['company'].index(x) < start_slice):\n",
    "                start_slice = client_info['company'].index(x)\n",
    "    client_info['company'] = remove_characters(client_info['company'][start_slice:end_slice+1])\n",
    "\n",
    "    generic_df = pd.DataFrame(generic_stats)\n",
    "    \n",
    "    \n",
    "\n",
    "    print(generic_stats, client_info)\n",
    "\n",
    "    clicks_table = stats_page_soup.find('table', attrs={'class':'PlainTable'}).find_all('tr')\n",
    "\n",
    "    individual_clicks = {\n",
    "        'pixels':[],\n",
    "        'company':[]\n",
    "    }\n",
    "    for index in range(1, len(clicks_table)):\n",
    "        row = clicks_table[index]\n",
    "        sections = row.find_all('td')\n",
    "        \n",
    "        link_clicked = sections[1]\n",
    "        link_clicked_href = link_clicked.find('a').get('href')\n",
    "\n",
    "        click_stats_link = sections[2].find('a').get('href')\n",
    "\n",
    "\n",
    "        # print(sections[1].find('a').get('href'))\n",
    "        if link_clicked_href in credentials[company]['bot_links']:\n",
    "            if not click_stats_link in individual_clicks['pixels']:\n",
    "                individual_clicks['pixels'].append(click_stats_link)\n",
    "        else:\n",
    "            if not click_stats_link in individual_clicks['company']:\n",
    "                individual_clicks['company'].append(click_stats_link)\n",
    "\n",
    "    os.mkdir(f'{os.getcwd()}\\\\company')\n",
    "    os.mkdir(f'{os.getcwd()}\\\\pixels')\n",
    "    for index in range(len(individual_clicks['pixels'])):\n",
    "        link = individual_clicks['pixels'][index]\n",
    "        click_stats_res = session.get(link)\n",
    "        click_stats_page = BeautifulSoup(click_stats_res.content, 'html.parser')\n",
    "        form = click_stats_page.find('form')\n",
    "        inputs = form.find_all('input')\n",
    "        input_dictionary={}\n",
    "        for x in inputs:\n",
    "           name= x.get('name')\n",
    "           value = x.get('value')\n",
    "           if(name != None and not name in input_dictionary):\n",
    "            input_dictionary[name]=value\n",
    "        csv_data = session.post(link, data=input_dictionary)\n",
    "        newFile = open(f'{os.getcwd()}\\\\pixels\\\\Recipients({index}).csv', 'w', newline='')\n",
    "        newFile.write(csv_data.text)\n",
    "        newFile.close()\n",
    "\n",
    "    for index in range(len(individual_clicks['company'])):\n",
    "        link = individual_clicks['company'][index]\n",
    "        click_stats_res = session.get(link)\n",
    "        click_stats_page = BeautifulSoup(click_stats_res.content, 'html.parser')\n",
    "        form = click_stats_page.find('form')\n",
    "        inputs = form.find_all('input')\n",
    "        input_dictionary={}\n",
    "        for x in inputs:\n",
    "           name= x.get('name')\n",
    "           value = x.get('value')\n",
    "           if(name != None and not name in input_dictionary):\n",
    "            input_dictionary[name]=value\n",
    "        csv_data = session.post(link, data=input_dictionary)\n",
    "        newFile = open(f'{os.getcwd()}\\\\company\\\\Recipients({index}).csv', 'w', newline='')\n",
    "        newFile.write(csv_data.text)\n",
    "        newFile.close()\n",
    "\n",
    "\n",
    "    ##run analysis\n",
    "    if client_info['company'] in clients:\n",
    "        analysis_and_visualisation(subject_line=client_info['subject_line'], company=client_info['company'], colours=clients[client_info['company']], generic_df=generic_df, handicap=handicap, abbrv='?utm_source')\n",
    "    else:\n",
    "        print(f'To run analysis please provide colours for the company: {client_info[\"company\"]}')\n",
    "get_basic_info(company, stats_url=stats_url)\n",
    "clear_directories()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01cf2e2fe5894d44bdffc1f9fc5ca6ca9931f6669129ee7e98bb7fd223434d06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
